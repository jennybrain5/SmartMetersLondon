{"paragraphs":[{"text":"%pyspark\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import MinMaxScaler\nfrom pyspark.ml.feature import StandardScaler\nimport pandas as pd\nimport numpy as np","user":"hduser","dateUpdated":"2019-02-03T14:13:59-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1548868538893_1924684457","id":"20190130-111538_1135471257","dateCreated":"2019-01-30T11:15:38-0600","dateStarted":"2019-02-03T14:13:59-0600","dateFinished":"2019-02-03T14:13:59-0600","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:31"},{"text":"%pyspark\n# Number of experiments to run\nn_exp=50","user":"hduser","dateUpdated":"2019-02-03T14:17:18-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1548868501160_-570807861","id":"20190130-111501_1163800837","dateCreated":"2019-01-30T11:15:01-0600","dateStarted":"2019-02-03T14:17:18-0600","dateFinished":"2019-02-03T14:17:18-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:32"},{"text":"%md\n### Time Series Clustering (MLLIB)\n","user":"hduser","dateUpdated":"2019-01-30T17:52:22-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Time Series Clustering (MLLIB)</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1548868585512_-1389403514","id":"20190130-111625_1251261468","dateCreated":"2019-01-30T11:16:25-0600","dateStarted":"2019-01-30T17:52:22-0600","dateFinished":"2019-01-30T17:52:22-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:33"},{"text":"%pyspark\n\n#Scaler:\n# 0 - No Scaling\n# 1 - Feature Scaling\nsc=0\n\n# Load data.\ndataset = hour_mat_agg\nvectorAssembler = VectorAssembler(inputCols = ['H0', 'H1', 'H2', 'H3', 'H4', 'H5', 'H6', 'H7', 'H8', 'H9', 'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'H17', 'H18', 'H19', 'H20', 'H21', 'H22', 'H23'], outputCol = 'features')\ndataset_rd = vectorAssembler.transform(dataset)\ndataset_rd = dataset_rd.select(['METER_ID','features'])\n\n\nif(sc==1):\n    \n    #scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n                            withStd=True, withMean=False)\n\n    # Compute summary statistics and generate MinMaxScalerModel\n    scalerModel = scaler.fit(dataset_rd)\n    # rescale each feature to range [min, max].\n    scaledData = scalerModel.transform(dataset_rd)\n    #print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n    dataset_rd=scaledData.drop(scaledData.features)\n    dataset_rd= dataset_rd.withColumnRenamed(\"scaledFeatures\",\"features\")\n\nclusters=3\n# Trains a k-means model.\nkmeans = KMeans().setK(clusters).setSeed(np.random.randint(1,101))\nmodel_win_1 = kmeans.fit(dataset_rd)\nsilhouette_win=-1\n\nfor i in range(n_exp):\n    kmeans = KMeans().setK(clusters).setSeed(np.random.randint(1,101))\n    model = kmeans.fit(dataset_rd)\n    predictions = model.transform(dataset_rd)\n    evaluator = ClusteringEvaluator()\n    silhouette = evaluator.evaluate(predictions)\n    print(\"Run %d - Silhouette = %f\" % (i, silhouette))\n    \n    if silhouette>silhouette_win:\n        silhouette_win=silhouette\n        model_win_1=model\n        winner_exp=i\n        pred_win_ts=predictions\n\nprint(\"\\nBest model found at experiment %d, Silhouete= %f\" %(winner_exp, silhouette_win))","user":"hduser","dateUpdated":"2019-02-03T14:17:21-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Run 0 - Silhouette = 0.594334\nRun 1 - Silhouette = 0.577195\nRun 2 - Silhouette = 0.593574\nRun 3 - Silhouette = 0.589484\nRun 4 - Silhouette = 0.587487\nRun 5 - Silhouette = 0.591907\nRun 6 - Silhouette = 0.587487\nRun 7 - Silhouette = 0.595828\nRun 8 - Silhouette = 0.577330\nRun 9 - Silhouette = 0.587487\nRun 10 - Silhouette = 0.597202\nRun 11 - Silhouette = 0.593574\nRun 12 - Silhouette = 0.585769\nRun 13 - Silhouette = 0.595112\nRun 14 - Silhouette = 0.588063\nRun 15 - Silhouette = 0.577460\nRun 16 - Silhouette = 0.587487\nRun 17 - Silhouette = 0.591907\nRun 18 - Silhouette = 0.597202\nRun 19 - Silhouette = 0.591907\nRun 20 - Silhouette = 0.728839\nRun 21 - Silhouette = 0.587354\nRun 22 - Silhouette = 0.577460\nRun 23 - Silhouette = 0.585769\nRun 24 - Silhouette = 0.577460\nRun 25 - Silhouette = 0.577460\nRun 26 - Silhouette = 0.594334\nRun 27 - Silhouette = 0.597202\nRun 28 - Silhouette = 0.732740\nRun 29 - Silhouette = 0.588901\nRun 30 - Silhouette = 0.588901\nRun 31 - Silhouette = 0.576954\nRun 32 - Silhouette = 0.577460\nRun 33 - Silhouette = 0.587487\nRun 34 - Silhouette = 0.577460\nRun 35 - Silhouette = 0.593574\nRun 36 - Silhouette = 0.728839\nRun 37 - Silhouette = 0.587487\nRun 38 - Silhouette = 0.595828\nRun 39 - Silhouette = 0.728839\nRun 40 - Silhouette = 0.590075\nRun 41 - Silhouette = 0.595112\nRun 42 - Silhouette = 0.587487\nRun 43 - Silhouette = 0.587487\nRun 44 - Silhouette = 0.593574\nRun 45 - Silhouette = 0.595828\nRun 46 - Silhouette = 0.730686\nRun 47 - Silhouette = 0.732023\nRun 48 - Silhouette = 0.587487\nRun 49 - Silhouette = 0.589484\n\nBest model found at experiment 28, Silhouete= 0.732740\n"}]},"apps":[],"jobName":"paragraph_1548868558232_52159944","id":"20190130-111558_364968528","dateCreated":"2019-01-30T11:15:58-0600","dateStarted":"2019-02-03T14:17:21-0600","dateFinished":"2019-02-03T14:40:15-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:34"},{"text":"%md\n### Features Clustering (MLLIB)\n","user":"hduser","dateUpdated":"2019-01-30T19:57:45-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Features Clustering (MLLIB)</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1548868626064_876810751","id":"20190130-111706_985369375","dateCreated":"2019-01-30T11:17:06-0600","dateStarted":"2019-01-30T19:57:45-0600","dateFinished":"2019-01-30T19:57:45-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:35"},{"text":"%pyspark\n#Scaler:\n# 0 - No Scaling\n# 1 - Feature Scaling\nsc=0\n\ndata=meters_db.select(['METER_ID','MEAN_MAX_H_TIME','MEAN_WD'])\n\nvectorAssembler = VectorAssembler(inputCols = ['MEAN_MAX_H_TIME','MEAN_WD'], outputCol = 'features')\ndataset_rd = vectorAssembler.transform(data)\ndataset_rd = dataset_rd.select(['METER_ID','features'])\n\n\nif(sc==1):\n    \n    #scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n                            withStd=True, withMean=False)\n\n    # Compute summary statistics and generate MinMaxScalerModel\n    scalerModel = scaler.fit(dataset_rd)\n    # rescale each feature to range [min, max].\n    scaledData = scalerModel.transform(dataset_rd)\n    #print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n    dataset_rd=scaledData.drop(scaledData.features)\n    dataset_rd= dataset_rd.withColumnRenamed(\"scaledFeatures\",\"features\")\n    \n    \nclusters=3\n# Trains a k-means model.\nkmeans = KMeans().setK(clusters).setSeed(np.random.randint(1,101))\nmodel_win_2 = kmeans.fit(dataset_rd)\nsilhouette_win=-1\n\nfor i in range(n_exp):\n    kmeans = KMeans().setK(clusters).setSeed(np.random.randint(1,101))\n    model = kmeans.fit(dataset_rd)\n    predictions = model.transform(dataset_rd)\n    evaluator = ClusteringEvaluator()\n    silhouette = evaluator.evaluate(predictions)\n    print(\"Run %d - Silhouette = %f\" % (i, silhouette))\n    \n    if silhouette>silhouette_win:\n        silhouette_win=silhouette\n        model_win_2=model\n        winner_exp=i\n        pred_win_feat=predictions\n\nprint(\"\\nBest model found at experiment %d, Silhouete= %f\" %(winner_exp, silhouette_win))","user":"hduser","dateUpdated":"2019-02-03T14:36:19-0600","config":{"colWidth":12,"fontSize":9,"enabled":false,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Run 0 - Silhouette = 0.448677\nRun 1 - Silhouette = 0.452081\n\nBest model found at experiment 1, Silhouete= 0.452081\n"}]},"apps":[],"jobName":"paragraph_1548868641098_428343478","id":"20190130-111721_2142334762","dateCreated":"2019-01-30T11:17:21-0600","dateStarted":"2019-01-30T15:38:31-0600","dateFinished":"2019-01-30T16:24:22-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:36"},{"text":"%md\n### Time Series clustering (TSlearn)","user":"hduser","dateUpdated":"2019-02-03T11:46:04-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Time Series clustering (TSlearn)</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1549215780072_-430012765","id":"20190203-114300_270920656","dateCreated":"2019-02-03T11:43:00-0600","dateStarted":"2019-02-03T11:46:04-0600","dateFinished":"2019-02-03T11:46:04-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:37"},{"text":"%pyspark\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tslearn.clustering import TimeSeriesKMeans\nfrom tslearn.datasets import CachedDatasets\nfrom tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n\ndata_pd=hour_mat_agg.select(hour_mat_agg.METER_ID).toPandas()\ndata=hour_mat_agg.drop(hour_mat_agg.METER_ID).drop(hour_mat_agg.CAT)\n#data=hour_mat.drop(hour_mat.METER_ID).drop(hour_mat.MAX_TIME).drop(hour_mat.CAT).drop(hour_mat.DATE)\n\nX_train=np.array(data.select(col(\"*\")).collect())","user":"hduser","dateUpdated":"2019-02-03T14:52:17-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1549215776983_-1091984104","id":"20190203-114256_1227054025","dateCreated":"2019-02-03T11:42:56-0600","dateStarted":"2019-02-03T14:52:17-0600","dateFinished":"2019-02-03T14:52:19-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:38"},{"text":"%pyspark\n\n#Scaler:\n# 0 - No Scaling\n# 1 - Feature Scaling\nsc=0\nclusters=3\nif(sc==1):\n    X_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\n\n\nsilhouette_win=-1\n\nfor i in range(n_exp):\n    km = TimeSeriesKMeans(n_clusters=clusters, verbose=False, random_state=np.random.randint(1,101))\n    y_pred = km.fit_predict(X_train)\n    pred_pd=pd.DataFrame(y_pred)\n    result = pd.concat([data_pd, pred_pd], axis=1, sort=False)\n    data_cl = spark.createDataFrame(result) \n\n    data0=result[result[0]==0]\n    data1=result[result[0]==1]\n    data2=result[result[0]==2]\n\n    data_cl=data_cl.withColumn(\"prediction\",data_cl['0']+1 ).drop(data_cl['0'])\n    predictions=dataset_rd.join(data_cl,dataset_rd.METER_ID==data_cl.METER_ID).drop(data_cl.METER_ID)\n    evaluator = ClusteringEvaluator()\n    silhouette = evaluator.evaluate(predictions)\n    print(\"Run %d - Silhouette = %f\" % (i, silhouette))\n    \n    if silhouette>silhouette_win:\n        silhouette_win=silhouette\n        winner_exp=i\n        pred_win_tslearn=predictions\n\nprint(\"\\nBest model found at experiment %d, Silhouete= %f\" %(winner_exp, silhouette_win))","user":"hduser","dateUpdated":"2019-02-03T14:55:01-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Run 0 - Silhouette = 0.577195\nRun 1 - Silhouette = 0.577195\nRun 2 - Silhouette = 0.587038\nRun 3 - Silhouette = 0.577195\nRun 4 - Silhouette = 0.577195\nRun 5 - Silhouette = 0.577195\nRun 6 - Silhouette = 0.587487\nRun 7 - Silhouette = 0.577195\nRun 8 - Silhouette = 0.587487\nRun 9 - Silhouette = 0.577195\nRun 10 - Silhouette = 0.587487\nRun 11 - Silhouette = 0.587487\nRun 12 - Silhouette = 0.577195\nRun 13 - Silhouette = 0.585159\nRun 14 - Silhouette = 0.587487\nRun 15 - Silhouette = 0.577195\nRun 16 - Silhouette = 0.577195\nRun 17 - Silhouette = 0.587487\nRun 18 - Silhouette = 0.587487\nRun 19 - Silhouette = 0.577195\nRun 20 - Silhouette = 0.587487\nRun 21 - Silhouette = 0.584498\nRun 22 - Silhouette = 0.587487\nRun 23 - Silhouette = 0.577195\nRun 24 - Silhouette = 0.577195\nRun 25 - Silhouette = 0.577195\nRun 26 - Silhouette = 0.587487\nRun 27 - Silhouette = 0.577195\nRun 28 - Silhouette = 0.577195\nRun 29 - Silhouette = 0.587487\nRun 30 - Silhouette = 0.585159\nRun 31 - Silhouette = 0.587487\nRun 32 - Silhouette = 0.585159\nRun 33 - Silhouette = 0.587487\nRun 34 - Silhouette = 0.577195\nRun 35 - Silhouette = 0.577195\nRun 36 - Silhouette = 0.577195\nRun 37 - Silhouette = 0.587487\nRun 38 - Silhouette = 0.587038\nRun 39 - Silhouette = 0.587487\nRun 40 - Silhouette = 0.577195\nRun 41 - Silhouette = 0.578071\nRun 42 - Silhouette = 0.587487\nRun 43 - Silhouette = 0.577195\nRun 44 - Silhouette = 0.577195\nRun 45 - Silhouette = 0.578071\nRun 46 - Silhouette = 0.577195\nRun 47 - Silhouette = 0.577195\nRun 48 - Silhouette = 0.577195\nRun 49 - Silhouette = 0.577195\n\nBest model found at experiment 14, Silhouete= 0.587487\n"}]},"apps":[],"jobName":"paragraph_1549215993112_-884524256","id":"20190203-114633_548255083","dateCreated":"2019-02-03T11:46:33-0600","dateStarted":"2019-02-03T14:55:01-0600","dateFinished":"2019-02-03T15:01:21-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:39"},{"text":"%md \n### Cluster Assignment for Information Households database","user":"hduser","dateUpdated":"2019-02-03T11:43:13-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Cluster Assignment for Information Households database</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1548886638661_-1200249874","id":"20190130-161718_406787527","dateCreated":"2019-01-30T16:17:18-0600","dateStarted":"2019-02-03T11:43:13-0600","dateFinished":"2019-02-03T11:43:13-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:40"},{"text":"%pyspark\n# Give correct numeration to found clusters\nclusters=meters_db.select(['METER_ID','MEAN_MONTH'])\nclusters=clusters.join(pred_win_ts.select(['METER_ID','prediction']),pred_win_ts.METER_ID==clusters.METER_ID).drop(pred_win_ts.METER_ID)\nclusters=clusters.groupBy('prediction').agg(sqlFunctions.avg(\"MEAN_MONTH\").alias(\"mean_pred\")).orderBy(\"prediction\")\n#clusters.show()\n\ncat_pd=clusters.toPandas()\nmax_c=cat_pd.loc[cat_pd['mean_pred'].idxmax()][0]\nmin_c=cat_pd.loc[cat_pd['mean_pred'].idxmin()][0]\nmeters_clus=pred_win_ts.drop(\"features\").withColumn('CATC', when(col(\"prediction\") == max_c, 1).when(col(\"prediction\") == min_c, 3).otherwise(2))\nmeters_clus=meters_clus.withColumn('CATC_NAME', when(col(\"prediction\") == max_c, \"High\").when(col(\"prediction\") == min_c, \"Low\").otherwise(\"Medium\")).drop(meters_clus.prediction)\n#meters_clus.show()\n\nhouseholds_clus=information_households.join(meters_clus, information_households.METER_ID==meters_clus.METER_ID).drop(meters_clus.METER_ID).drop(information_households.ID)\n\nclusters2=meters_db.select(['METER_ID','MEAN_MONTH'])\nclusters2=clusters2.join(pred_win_tslearn.select(['METER_ID','prediction']),pred_win_tslearn.METER_ID==clusters2.METER_ID).drop(pred_win_tslearn.METER_ID)\nclusters2=clusters2.groupBy('prediction').agg(sqlFunctions.avg(\"MEAN_MONTH\").alias(\"mean_pred\")).orderBy(\"prediction\")\n#clusters.show()\n\ncat_pd=clusters2.toPandas()\nmax_c=cat_pd.loc[cat_pd['mean_pred'].idxmax()][0]\nmin_c=cat_pd.loc[cat_pd['mean_pred'].idxmin()][0]\nmeters_clus2=pred_win_tslearn.drop(\"features\").withColumn('CATC_TS', when(col(\"prediction\") == max_c, 1).when(col(\"prediction\") == min_c, 3).otherwise(2))\nmeters_clus2=meters_clus2.withColumn('CATC_TS_NAME', when(col(\"prediction\") == max_c, \"High\").when(col(\"prediction\") == min_c, \"Low\").otherwise(\"Medium\")).drop(meters_clus2.prediction)\n#meters_clus.show()\n\nhouseholds_clus=households_clus.join(meters_clus2, households_clus.METER_ID==meters_clus2.METER_ID).drop(meters_clus2.METER_ID)\nhouseholds_clus.show()\n\n\n\n\n\n\n\n\n\n","user":"hduser","dateUpdated":"2019-02-03T15:24:03-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","lineNumbers":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+-------+---------+--------------------+-----------+---+-----------+----+---------+-------+------------+\n| METER_ID|STD_TOU|ACORN_CAT|      ACORN_CAT_NAME|ACORN_GROUP|CAT|   CAT_NAME|CATC|CATC_NAME|CATC_TS|CATC_TS_NAME|\n+---------+-------+---------+--------------------+-----------+---+-----------+----+---------+-------+------------+\n|MAC000032|    Std|        5|     Urban Adversity|    ACORN-Q|  3|  Stretched|   2|   Medium|      3|         Low|\n|MAC000041|    Std|        5|     Urban Adversity|    ACORN-Q|  3|  Stretched|   3|      Low|      3|         Low|\n|MAC000338|    Std|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC000925|    Std|        4|Financially Stret...|    ACORN-K|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC000976|    ToU|        5|     Urban Adversity|    ACORN-O|  3|  Stretched|   3|      Low|      3|         Low|\n|MAC001430|    Std|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC001761|    Std|        4|Financially Stret...|    ACORN-L|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC001803|    Std|        2|   Rising Prosperity|    ACORN-D|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC002560|    ToU|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC002980|    Std|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC003083|    Std|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC003509|    Std|        3|Comfortable Comun...|    ACORN-F|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC004029|    Std|        1|  Affluent Achievers|    ACORN-C|  1|   Affluent|   3|      Low|      2|      Medium|\n|MAC004358|    Std|        5|     Urban Adversity|    ACORN-Q|  3|  Stretched|   3|      Low|      3|         Low|\n|MAC004532|    Std|        4|Financially Stret...|    ACORN-L|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC004692|    Std|        4|Financially Stret...|    ACORN-K|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC004897|    Std|        3|Comfortable Comun...|    ACORN-J|  2|Comfortable|   2|   Medium|      2|      Medium|\n|MAC005122|    ToU|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      2|      Medium|\n|MAC005232|    Std|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      3|         Low|\n|MAC005271|    ToU|        2|   Rising Prosperity|    ACORN-E|  2|Comfortable|   3|      Low|      3|         Low|\n+---------+-------+---------+--------------------+-----------+---+-----------+----+---------+-------+------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1548884368611_777392957","id":"20190130-153928_1794987324","dateCreated":"2019-01-30T15:39:28-0600","dateStarted":"2019-02-03T15:24:03-0600","dateFinished":"2019-02-03T15:24:58-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:41"},{"text":"%md\n## Cluster vs Label \nSee how well initial labels match cluster labels\n","user":"hduser","dateUpdated":"2019-01-30T20:02:21-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Cluster vs Label</h2>\n<p>See how well initial labels match cluster labels</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1548892272414_290231081","id":"20190130-175112_635109889","dateCreated":"2019-01-30T17:51:12-0600","dateStarted":"2019-01-30T20:02:21-0600","dateFinished":"2019-01-30T20:02:21-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:42"},{"text":"%pyspark\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\ntemp=households_clus.select([\"CATC\",\"CAT\"])\ntemp=temp.withColumn(\"CATC\", temp.CATC.cast(DoubleType())).withColumn(\"CAT\", temp.CAT.cast(DoubleType()))\npredictionAndLabels_df = sc.parallelize(temp.collect())\nmetrics = MulticlassMetrics(predictionAndLabels_df)\nprint(\"Confusion Matrix for MLLib Clustering\")\nprint(metrics.confusionMatrix())\n\ntemp=households_clus.select([\"CATC_TS\",\"CAT\"])\ntemp=temp.withColumn(\"CATC_TS\", temp.CATC_TS.cast(DoubleType())).withColumn(\"CAT\", temp.CAT.cast(DoubleType()))\npredictionAndLabels_df = sc.parallelize(temp.collect())\nmetrics = MulticlassMetrics(predictionAndLabels_df)\nprint(\"Confusion Matrix for TSLearn Clustering\")\nprint(metrics.confusionMatrix())\n","user":"hduser","dateUpdated":"2019-02-03T15:35:18-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Confusion Matrix for MLLib Clustering\nDenseMatrix([[ 133.,    0.,  199.],\n             [ 755.,   35., 3346.],\n             [  72.,   19.,  950.]])\nConfusion Matrix for TSLearn Clustering\nDenseMatrix([[  42.,  165.,  125.],\n             [ 177., 1403., 2556.],\n             [   9.,  188.,  844.]])\n"}]},"apps":[],"jobName":"paragraph_1548887206354_1849646475","id":"20190130-162646_777202633","dateCreated":"2019-01-30T16:26:46-0600","dateStarted":"2019-02-03T15:35:18-0600","dateFinished":"2019-02-03T15:35:27-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:43"},{"text":"%pyspark\nhouseholds_clusters = households_clus.select(row_number().over(Window().orderBy(\"METER_ID\")).alias(\"ID\"), col(\"*\"))\nhouseholds_clusters.write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(\"hdfs://big0.iie.org.mx:9000/JSGP/datasets/london/analytics/households_clusters.csv\")","user":"hduser","dateUpdated":"2019-02-03T15:35:52-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1548891597175_875806447","id":"20190130-173957_1976101510","dateCreated":"2019-01-30T17:39:57-0600","dateStarted":"2019-02-03T15:35:52-0600","dateFinished":"2019-02-03T15:35:56-0600","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:44"},{"text":"%pyspark\n","user":"hduser","dateUpdated":"2019-02-03T15:31:22-0600","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1549229482742_-423313742","id":"20190203-153122_1425046789","dateCreated":"2019-02-03T15:31:22-0600","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:45"}],"name":"JSGP/london/analytics/clustering","id":"2E4X13J3K","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}