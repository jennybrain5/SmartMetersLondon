{"paragraphs":[{"text":"%md\n# ![Spark Logo](https://spark.apache.org/images/spark-logo-trademark.png)\n# **Contador de palabras con Spark**\n\nEn esta práctica usaremos las bases que conocemos de Spark DataFrames para construir el hola mundo del mundo Big Data, un contador de palabras.\n\nEl texto plano, es uno de los tipos de datos con mayor abundancia en el mundo actual. Spark nos facilita procesar grandes volumenes de este tipo de datos. En esta notebook codificaremos una aplicación para encontrar las palabras más comunes en la literatura de William Shakespeare. Esta aplicación puede ser transladada a otras áres de aplicación, como contar las palabras más comunes en Wikipedia.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1><img src=\"https://spark.apache.org/images/spark-logo-trademark.png\" alt=\"Spark Logo\" /></h1>\n<h1><strong>Contador de palabras con Spark</strong></h1>\n<p>En esta práctica usaremos las bases que conocemos de Spark DataFrames para construir el hola mundo del mundo Big Data, un contador de palabras.</p>\n<p>El texto plano, es uno de los tipos de datos con mayor abundancia en el mundo actual. Spark nos facilita procesar grandes volumenes de este tipo de datos. En esta notebook codificaremos una aplicación para encontrar las palabras más comunes en la literatura de William Shakespeare. Esta aplicación puede ser transladada a otras áres de aplicación, como contar las palabras más comunes en Wikipedia.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131002_1192963279","id":"20180709-193017_1493444029","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:55"},{"text":"%md\n## Creando un DataFrame\n\nPrimero, crearemos un DataFrame usando una lista de tuplas de python. Usemos [`createDataFrame`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SQLContext.createDataFrame) para crear nuestro DataFrame.","user":"hduser","dateUpdated":"2018-08-06T10:43:59-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Creando un DataFrame</h2>\n<p>Primero, crearemos un DataFrame usando una lista de tuplas de python. Usemos <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SQLContext.createDataFrame\"><code>createDataFrame</code></a> para crear nuestro DataFrame.</p>\n"}]},"apps":[],"jobName":"paragraph_1533570131004_1190654786","id":"20180709-193049_761334744","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-06T10:43:59-0500","dateFinished":"2018-08-06T10:43:59-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:56"},{"text":"%pyspark\nwordsDF = spark.createDataFrame([('gato',), ('elefante',), ('rata',), ('rata',), ('gato', )], ['palabra'])\nwordsDF.show()\nprint type(wordsDF)\nwordsDF.printSchema()","user":"hduser","dateUpdated":"2018-10-25T16:33:36-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533570131004_1190654786","id":"20180709-194610_704860005","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-10-25T16:33:36-0500","dateFinished":"2018-10-25T16:34:30-0500","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:57"},{"text":"%md\n### Usando funciones de DataFrames\nAhora, vamos a crear un nuevo DataFrame usando `wordsDF`, mediante una operación que concatene la letra `s` a cada entrada del DataFrame. Para hacer esto, utiliza la operación [`select`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.select) para generar una columna que toma la columna existente y concatena la letra `s`. Usarás las funciones [`concat`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.concat) y [`lit`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lit) del módulo [`pyspark.sql.functions`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions).\n\nEn las celdas de esta notebook encontrarás la etiqueta `<RELLENA>`, que indica que debes sustituir la etiqueta con tu código.\n\n> Nota:\n> Asegurate de que el nuevo DataFrame contenga una columna que lleve como nombre 'palabra', puedes usar la función [alias](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.alias) para renombrar una columna.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Usando funciones de DataFrames</h3>\n<p>Ahora, vamos a crear un nuevo DataFrame usando <code>wordsDF</code>, mediante una operación que concatene la letra <code>s</code> a cada entrada del DataFrame. Para hacer esto, utiliza la operación <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.select\"><code>select</code></a> para generar una columna que toma la columna existente y concatena la letra <code>s</code>. Usarás las funciones <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.concat\"><code>concat</code></a> y <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lit\"><code>lit</code></a> del módulo <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions\"><code>pyspark.sql.functions</code></a>.</p>\n<p>En las celdas de esta notebook encontrarás la etiqueta <code>&lt;RELLENA&gt;</code>, que indica que debes sustituir la etiqueta con tu código.</p>\n<blockquote>\n  <p>Nota:<br/>Asegurate de que el nuevo DataFrame contenga una columna que lleve como nombre &lsquo;palabra&rsquo;, puedes usar la función <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.alias\">alias</a> para renombrar una columna.</p>\n</blockquote>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131005_1190270037","id":"20180709-194657_24738719","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:58"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfrom pyspark.sql.functions import lit, concat\n\npluralDF =wordsDF.select(concat(wordsDF.palabra,lit('s')).alias('plural'))\npluralDF.show()\n# pluralDF =wordsDF.select(wordsDF.palabra,concat(wordsDF.palabra,lit('s')).alias('plural'))\n\n#newDF=wordsDF.join(wordsDF,'plural').select(wordsDF.palabra, pluralDF.plural)\n#df.join(df2, 'name').select(df.name, df2.height).collect()\n\n\n#newDF.show()","user":"hduser","dateUpdated":"2018-08-08T10:10:39-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+\n|   plural|\n+---------+\n|    gatos|\n|elefantes|\n|    ratas|\n|    ratas|\n|    gatos|\n+---------+\n\n"}]},"apps":[],"jobName":"paragraph_1533570131005_1190270037","id":"20180709-195455_2030108643","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:10:39-0500","dateFinished":"2018-08-08T10:10:39-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:59"},{"text":"%md\n### Tamaño de cada palabra\n\nAhora, usarás la función [`length`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.length) para contar el número de caracteres en cada palabra.  Puedes encontrar la función [`length`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.length) en el módulo `pyspark.sql.functions`.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Tamaño de cada palabra</h3>\n<p>Ahora, usarás la función <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.length\"><code>length</code></a> para contar el número de caracteres en cada palabra. Puedes encontrar la función <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.length\"><code>length</code></a> en el módulo <code>pyspark.sql.functions</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131006_1191424284","id":"20180709-195609_953595191","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:60"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfrom pyspark.sql.functions import length\n\npluralLengthsDF = pluralDF.select(pluralDF.plural,length(pluralDF.plural).alias('length'))\npluralLengthsDF.show()","user":"hduser","dateUpdated":"2018-08-08T10:10:45-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+------+\n|   plural|length|\n+---------+------+\n|    gatos|     5|\n|elefantes|     9|\n|    ratas|     5|\n|    ratas|     5|\n|    gatos|     5|\n+---------+------+\n\n"}]},"apps":[],"jobName":"paragraph_1533570131006_1191424284","id":"20180709-200155_254005710","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:10:45-0500","dateFinished":"2018-08-08T10:10:45-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:61"},{"text":"%md\n## Contando el número de veces que aparece una palabra con SparkSQL y DataFrames\n\nContarémos el número de veces que una palabra aparece en la columna `palabra`. Existen múltiples maneras de llevar a cabo esta tarea, pero unas pueden ser mucho más eficientes que otras.\n\nUna manera ingenua sería usar `collect()` para obtener a los elementos del DataFrame y realizar el conteo en el 'Driver' del clúster. Esto solo funcionaría si el conjunto de datos es pequeño, si no lo es, los datos desbordarían la memoria del nodo, congelandolo.\n\nBusquemos la manera de realizar la tarea de forma escalable, para que podamos realizarla en paralelo en múltiples nodos con conjuntos de datos de terabytes a petabytes.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Contando el número de veces que aparece una palabra con SparkSQL y DataFrames</h2>\n<p>Contarémos el número de veces que una palabra aparece en la columna <code>palabra</code>. Existen múltiples maneras de llevar a cabo esta tarea, pero unas pueden ser mucho más eficientes que otras.</p>\n<p>Una manera ingenua sería usar <code>collect()</code> para obtener a los elementos del DataFrame y realizar el conteo en el &lsquo;Driver&rsquo; del clúster. Esto solo funcionaría si el conjunto de datos es pequeño, si no lo es, los datos desbordarían la memoria del nodo, congelandolo.</p>\n<p>Busquemos la manera de realizar la tarea de forma escalable, para que podamos realizarla en paralelo en múltiples nodos con conjuntos de datos de terabytes a petabytes.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131007_1191039535","id":"20180709-200014_2140267346","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:62"},{"text":"%md\n### Usando groupBy y count\n\nLa función [`groupBy`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy) de los DataFrame nos retorna un objeto [`GroupedData`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData), este tipo de objeto nos permite llevar a cabo funciones de agregación en los datos.\n\nPara contar las palabras, podemos agrupar el DataFrame por la columna `palabra` y usar la función de agregación [`count`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.count) para encontrar el número de veces que la palabra aparece en el DataFrame.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Usando groupBy y count</h3>\n<p>La función <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy\"><code>groupBy</code></a> de los DataFrame nos retorna un objeto <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData\"><code>GroupedData</code></a>, este tipo de objeto nos permite llevar a cabo funciones de agregación en los datos.</p>\n<p>Para contar las palabras, podemos agrupar el DataFrame por la columna <code>palabra</code> y usar la función de agregación <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.count\"><code>count</code></a> para encontrar el número de veces que la palabra aparece en el DataFrame.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131007_1191039535","id":"20180709-200426_1433713121","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:63"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nwordCountsDF = (wordsDF\n            .groupBy('palabra')\n            .count())\nwordCountsDF.show()\n\n#dataDF.groupBy('ocupacion').count().show(truncate=False)","user":"hduser","dateUpdated":"2018-08-08T10:10:48-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+-----+\n| palabra|count|\n+--------+-----+\n|    gato|    2|\n|elefante|    1|\n|    rata|    2|\n+--------+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1533570131008_1176803826","id":"20180709-201053_413215542","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:10:48-0500","dateFinished":"2018-08-08T10:10:49-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:64"},{"text":"%md\n## Palabras únicas y valores promedio\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Palabras únicas y valores promedio</h2>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131008_1176803826","id":"20180709-201709_1678453142","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:65"},{"text":"%md\n### Palabras únicas\n\nCalcula el número de palabras únicas en `wordsDF`. Utiliza `wordCountsDF`, el DataFrame creado anteriormente para facilitar la tarea.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Palabras únicas</h3>\n<p>Calcula el número de palabras únicas en <code>wordsDF</code>. Utiliza <code>wordCountsDF</code>, el DataFrame creado anteriormente para facilitar la tarea.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131009_1176419077","id":"20180709-201757_1430973230","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:66"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nuniqueWordsCount = wordCountsDF.count()\nprint uniqueWordsCount","user":"hduser","dateUpdated":"2018-08-08T10:10:52-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"3\n"}]},"apps":[],"jobName":"paragraph_1533570131009_1176419077","id":"20180709-201914_1444390746","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:10:52-0500","dateFinished":"2018-08-08T10:10:53-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67"},{"text":"%md\n### Promedio de aparición de palabras\n\nEncuentra el promedio de aparición de palabras en `wordCountsDF`.\n\nUsa [`mean`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.mean) de [`GroupedData`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData) para llevar acabo la tarea.  Cuando usas `groupBy` no es necesario pasar ningúna columna como argumento, ésta unicamente preparará al DataFrame para poder usar funciones de agregación tales como `mean`.\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Promedio de aparición de palabras</h3>\n<p>Encuentra el promedio de aparición de palabras en <code>wordCountsDF</code>.</p>\n<p>Usa <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData.mean\"><code>mean</code></a> de <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData\"><code>GroupedData</code></a> para llevar acabo la tarea. Cuando usas <code>groupBy</code> no es necesario pasar ningúna columna como argumento, ésta unicamente preparará al DataFrame para poder usar funciones de agregación tales como <code>mean</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131010_1177573323","id":"20180709-202001_182717644","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:68"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\naverageCount = (wordCountsDF\n            .groupBy()\n            .mean()\n            .first()[0])\n\nprint averageCount","user":"hduser","dateUpdated":"2018-08-08T10:10:55-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1.66666666667\n"}]},"apps":[],"jobName":"paragraph_1533570131010_1177573323","id":"20180709-202525_1443422543","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:10:56-0500","dateFinished":"2018-08-08T10:10:56-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:69"},{"text":"%md\nLa celda de arriba debe imprimir:\n\n1.66666666667\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>La celda de arriba debe imprimir:</p>\n<p>1.66666666667</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131011_1177188575","id":"20180709-222241_994803306","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:70"},{"text":"%md\n## Aplicar el contador de palabras a un archivo de texto\n\nDeberás aplicar lo que aprendiste para contar las palabras en un archivo de texto. Deberás generar una función `wordCount`; aprender a lidiar con problemas con letras mayúsculas, minúsculas y puntuación; crear DataFrames desde una fuente de datos.\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Aplicar el contador de palabras a un archivo de texto</h2>\n<p>Deberás aplicar lo que aprendiste para contar las palabras en un archivo de texto. Deberás generar una función <code>wordCount</code>; aprender a lidiar con problemas con letras mayúsculas, minúsculas y puntuación; crear DataFrames desde una fuente de datos.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131011_1177188575","id":"20180709-202756_345273003","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:71"},{"text":"%md\n### Función WordCount\nCompleta la función `WordCount` para contar las palabras de un DataFrame. Puedes reutilizar las técnicas que utilizaste anteriormente en la notebook. La función recibirá como entrada un DataFrame con una palabra en cada entrada y retornará un DataFrame que contiene en cada entrada una palabra con su conteo respectivo.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Función WordCount</h3>\n<p>Completa la función <code>WordCount</code> para contar las palabras de un DataFrame. Puedes reutilizar las técnicas que utilizaste anteriormente en la notebook. La función recibirá como entrada un DataFrame con una palabra en cada entrada y retornará un DataFrame que contiene en cada entrada una palabra con su conteo respectivo.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131012_1175264830","id":"20180709-202843_2075838860","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:72"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\ndef wordCount(wordListDF):\n    \"\"\"Crea un DataFrame con el conteo de palabras\n\n    Args:\n        wordListDF (DataFrame de str): Un DataFrame que contiene una columna tipo string con nombre 'palabra'.\n\n    Returns:\n        DataFrame de (str, int): Un DataFrame que contiene las columnas 'palabra' y 'count'.\n    \"\"\"\n    \n    DF = wordListDF.groupBy('palabra').count()\n    \n    DF=DF.select(DF.palabra,DF['count'].alias('cuenta'))\n# la columna DF['count'] no se puede llamar con DF.count porque count es una palabra del sistema\n    \n    return DF\n\nwordCount(wordsDF).show()\n","user":"hduser","dateUpdated":"2018-08-08T10:11:01-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------+------+\n| palabra|cuenta|\n+--------+------+\n|    gato|     2|\n|elefante|     1|\n|    rata|     2|\n+--------+------+\n\n"}]},"apps":[],"jobName":"paragraph_1533570131012_1175264830","id":"20180709-203952_277827462","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:11:01-0500","dateFinished":"2018-08-08T10:11:02-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:73"},{"text":"%md\n### Mayúsculas, minúsculas y puntuación\n\nLas fuentes de datos no estructuradas del mundo real son más complejas que las vistas hasta ahora. Así que tendrás que lidiar con algunas complicaciones:\n\n- Las palabras deberán ser contadas independientemente de su capitalización (ejemplo, spark y Spark es la misma palabra)\n- Cualquier signo de puntuación deberá ser eliminado.\n- Espacios antes y después del texto deberán ser eliminados.\n\nCompleta la función `removePunctuation` para que convierta todas las letras a minúsculas, remueva signos de puntuación, y elimine espacios antes y después en del texto.\nUsa la función [regexp_replace](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.regexp_replace) del módulo `pyspark.sql.functions`, en conjunto con la expresión `\\p{Punct}` para eliminar signos de puntuación. Si quieres conocer más sobre expresiones regulares puedes revisar el siguiente [tutorial](https://developers.google.com/edu/python/regular-expressions) de Google.\n\nUsa las funciones [`trim`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.trim) y [`lower`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lower) del módulo [pyspark.sql.functions](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions) para remover espacios sobrantes y convertir letras mayúsculas a minúsculas respectivamente.\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Mayúsculas, minúsculas y puntuación</h3>\n<p>Las fuentes de datos no estructuradas del mundo real son más complejas que las vistas hasta ahora. Así que tendrás que lidiar con algunas complicaciones:</p>\n<ul>\n  <li>Las palabras deberán ser contadas independientemente de su capitalización (ejemplo, spark y Spark es la misma palabra)</li>\n  <li>Cualquier signo de puntuación deberá ser eliminado.</li>\n  <li>Espacios antes y después del texto deberán ser eliminados.</li>\n</ul>\n<p>Completa la función <code>removePunctuation</code> para que convierta todas las letras a minúsculas, remueva signos de puntuación, y elimine espacios antes y después en del texto.<br/>Usa la función <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.regexp_replace\">regexp_replace</a> del módulo <code>pyspark.sql.functions</code>, en conjunto con la expresión <code>\\p{Punct}</code> para eliminar signos de puntuación. Si quieres conocer más sobre expresiones regulares puedes revisar el siguiente <a href=\"https://developers.google.com/edu/python/regular-expressions\">tutorial</a> de Google.</p>\n<p>Usa las funciones <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.trim\"><code>trim</code></a> y <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lower\"><code>lower</code></a> del módulo <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions\">pyspark.sql.functions</a> para remover espacios sobrantes y convertir letras mayúsculas a minúsculas respectivamente.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131013_1174880081","id":"20180709-204228_1296401012","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:74"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfrom pyspark.sql.functions import regexp_replace, trim, col, lower\n\ndef removePunctuation(column):\n    \"\"\"Remueve puntuación, cambia a letras minusculas, y elimina espacios antes y despues de la cadena.\n\n    Notas:\n        Solo espacios, letras y numeros deben mantenerse. Cualquier otro caracter debe ser eliminado.\n        Ej., it's se convierte en its. \n        \n        Los espacios antes y despues del texto deberan eliminarse \n        despues de eliminar signos de puntuacion.\n        \n\n    Args:\n        column (Column): Una columna.\n\n    Returns:\n        column: Una columna que lleva como nombre 'oracion', la cual fue preprocesada.\n    \"\"\"\n    \n\n\n\n    column = lower(column)#Convierte mayusculas a minusculas\n    column = regexp_replace(column, '\\p{Punct}', '')#Elimina puntuacion\n    column = trim(column)#Elimina espacios sobrantes al inicio y fin del texto\n    column = column.alias(\"oracion\")\n    return column\n\nsentenceDF = sqlContext.createDataFrame([('Hola, tu!',),\n                                         (' Sin guion_bajo!',),\n                                         (' *      Remover puntuacion y despues espacios  * ',)], ['oracion'])\nsentenceDF.show(truncate=False)\n(sentenceDF\n         .select(removePunctuation(col('oracion')))\n         .show(truncate=False))\n","user":"hduser","dateUpdated":"2018-08-08T10:11:06-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------------------------------------------+\n|oracion                                          |\n+-------------------------------------------------+\n|Hola, tu!                                        |\n| Sin guion_bajo!                                 |\n| *      Remover puntuacion y despues espacios  * |\n+-------------------------------------------------+\n\n+-------------------------------------+\n|oracion                              |\n+-------------------------------------+\n|hola tu                              |\n|sin guionbajo                        |\n|remover puntuacion y despues espacios|\n+-------------------------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1533570131014_1176034328","id":"20180709-205136_643178247","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:11:06-0500","dateFinished":"2018-08-08T10:11:07-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:75"},{"text":"%md\nLa celda de arriba debe imprimir:\n\nhola tu\nsin guionbajo\nremover puntuacion y despues espacios","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>La celda de arriba debe imprimir:</p>\n<p>hola tu<br/>sin guionbajo<br/>remover puntuacion y despues espacios</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131015_1175649579","id":"20180709-210203_549628123","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:76"},{"text":"%md\n### Cargando un archivo de texto \n\nEl archivo `shakespeare.txt`, contiene la literatura completa de William Shakespeare, puedes obtenerla desde el siguiente enlace [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) parte del [Proyecto Gutenberg](http://www.gutenberg.org/wiki/Main_Page).\n\nAhora, cargarás desde HDFS el archivo de texto `shakespeare.txt` a un DataFrame de Spark. Usa la función [`text()`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.text) para leer el archivo desde HDFS. Aplica la función `removePunctuation()` que definiste en una celda anterior usando la transformación `select()`, para eliminar puntuación y cambiar el texto a letras minúsculas. Usarémos la función `show()` para visualizar algunas entradas del DataFrame, ya que el contenido del archivo es extenso.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Cargando un archivo de texto</h3>\n<p>El archivo <code>shakespeare.txt</code>, contiene la literatura completa de William Shakespeare, puedes obtenerla desde el siguiente enlace <a href=\"http://www.gutenberg.org/ebooks/100\">Complete Works of William Shakespeare</a> parte del <a href=\"http://www.gutenberg.org/wiki/Main_Page\">Proyecto Gutenberg</a>.</p>\n<p>Ahora, cargarás desde HDFS el archivo de texto <code>shakespeare.txt</code> a un DataFrame de Spark. Usa la función <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.text\"><code>text()</code></a> para leer el archivo desde HDFS. Aplica la función <code>removePunctuation()</code> que definiste en una celda anterior usando la transformación <code>select()</code>, para eliminar puntuación y cambiar el texto a letras minúsculas. Usarémos la función <code>show()</code> para visualizar algunas entradas del DataFrame, ya que el contenido del archivo es extenso.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131015_1175649579","id":"20180709-210122_855358268","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:77"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfileName = \"hdfs://big0.iie.org.mx:9000/JSGP/datasets/shakespeare.txt\"#Direccion a shakespeare.txt en HDFS\n\nshakespeareDF = spark.read.text(fileName).select(removePunctuation(col('value')))\nshakespeareDF.show(15, truncate=False)","user":"hduser","dateUpdated":"2018-08-08T10:44:06-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------------------------------------------------------------------------+\n|oracion                                                                    |\n+---------------------------------------------------------------------------+\n|the project gutenberg ebook of the complete works of william shakespeare by|\n|william shakespeare                                                        |\n|                                                                           |\n|this ebook is for the use of anyone anywhere at no cost and with           |\n|almost no restrictions whatsoever  you may copy it give it away or         |\n|reuse it under the terms of the project gutenberg license included         |\n|with this ebook or online at wwwgutenbergorg                               |\n|                                                                           |\n|this is a copyrighted project gutenberg ebook details below                |\n|please follow the copyright guidelines in this file                        |\n|                                                                           |\n|title the complete works of william shakespeare                            |\n|                                                                           |\n|author william shakespeare                                                 |\n|                                                                           |\n+---------------------------------------------------------------------------+\nonly showing top 15 rows\n\n"}]},"apps":[],"jobName":"paragraph_1533570131016_1173725834","id":"20180709-210124_946867636","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:44:06-0500","dateFinished":"2018-08-08T10:44:07-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:78"},{"text":"%md\n### Palabras desde lineas\n\nAntes de poder aplicar `wordCount()`, debemos resolver dos problemas con nuestro DataFrame:\n\n- Debemos dividir cada oración por espacios para obtener palabras\n- Debemos filtrar lineas vacías\n\nAplica una transformación que divida cada 'oracion' en el DataFrame por sus espacios, después, transforma el DataFrame que contiene listas de palabras en cada entrada a un DataFrame que contenga una palabra en cada entrada.\nPara esta tarea, utiliza las funciones [`split`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.split) y [`explode`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.explode), que forman parte del módulo [pyspark.sql.functions](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions).\n\nUna vez que tengas un DataFrame con una palabra en cada entrada, aplica un filtrado usando [`filter`](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.filter) para remover entradas que contienen `''`.\n\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Palabras desde lineas</h3>\n<p>Antes de poder aplicar <code>wordCount()</code>, debemos resolver dos problemas con nuestro DataFrame:</p>\n<ul>\n  <li>Debemos dividir cada oración por espacios para obtener palabras</li>\n  <li>Debemos filtrar lineas vacías</li>\n</ul>\n<p>Aplica una transformación que divida cada &lsquo;oracion&rsquo; en el DataFrame por sus espacios, después, transforma el DataFrame que contiene listas de palabras en cada entrada a un DataFrame que contenga una palabra en cada entrada.<br/>Para esta tarea, utiliza las funciones <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.split\"><code>split</code></a> y <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.explode\"><code>explode</code></a>, que forman parte del módulo <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions\">pyspark.sql.functions</a>.</p>\n<p>Una vez que tengas un DataFrame con una palabra en cada entrada, aplica un filtrado usando <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.filter\"><code>filter</code></a> para remover entradas que contienen <code>&#39;&#39;</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131016_1173725834","id":"20180709-211356_1602945370","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:79"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfrom pyspark.sql.functions import split, explode\n\n# shakeWordsDF = (shakespeareDF\n #                .<RELLENA>\n #                .<RELLENA>\n#                )\n               \n               \nshakeWordsDF = (shakespeareDF\n                .select(explode(split(shakespeareDF.oracion, '(\\n*)(\\s+)')).alias('palabra'))\n                .filter(\"palabra !=''\"))\n\n\"\"\"|# (\\n*) para saltos de linea y (\\s+) para uno o más espacios\"\"\"\nshakeWordsDF.show()\nshakeWordsDFCount = shakeWordsDF.count()\nprint shakeWordsDFCount","user":"hduser","dateUpdated":"2018-08-08T10:44:15-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+\n|    palabra|\n+-----------+\n|        the|\n|    project|\n|  gutenberg|\n|      ebook|\n|         of|\n|        the|\n|   complete|\n|      works|\n|         of|\n|    william|\n|shakespeare|\n|         by|\n|    william|\n|shakespeare|\n|       this|\n|      ebook|\n|         is|\n|        for|\n|        the|\n|        use|\n+-----------+\nonly showing top 20 rows\n\n903705\n"}]},"apps":[],"jobName":"paragraph_1533570131017_1173341086","id":"20180709-211906_1586639366","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:44:15-0500","dateFinished":"2018-08-08T10:44:18-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:80"},{"text":"%md\n### Contando las palabras\nAhora que tienes un DataFrame que contiene una palabra en cada entrada, podrás aplicar la función wordCount().\n\nVisualizaremos las primeras 20 palabras más utilizadas en el texto  usando `show()`, deberás usar el método [`orderBy`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.orderBy) para ordenar el DataFrame por la columna `count`. Recuerda que puedes usar `desc()` para invertir el ordenamiento.","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Contando las palabras</h3>\n<p>Ahora que tienes un DataFrame que contiene una palabra en cada entrada, podrás aplicar la función wordCount().</p>\n<p>Visualizaremos las primeras 20 palabras más utilizadas en el texto usando <code>show()</code>, deberás usar el método <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.orderBy\"><code>orderBy</code></a> para ordenar el DataFrame por la columna <code>count</code>. Recuerda que puedes usar <code>desc()</code> para invertir el ordenamiento.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131017_1173341086","id":"20180709-212013_156580003","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:81"},{"text":"%pyspark\n# Reemplaza <Rellena> con tu codigo\nfrom pyspark.sql.functions import desc\n\n\ntopWordsAndCountsDF = wordCount(shakeWordsDF)\n#topWordsAndCountsDF.show()\ntopWordsAndCountsDF= topWordsAndCountsDF.orderBy(topWordsAndCountsDF.cuenta.desc())\ntopWordsAndCountsDF.show(20, truncate=False)\n","user":"hduser","dateUpdated":"2018-08-08T10:44:20-0500","config":{"enabled":true,"results":{},"editorMode":"ace/mode/python","editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+------+\n|palabra|cuenta|\n+-------+------+\n|the    |27825 |\n|and    |26791 |\n|i      |20681 |\n|to     |19261 |\n|of     |18289 |\n|a      |14667 |\n|you    |13716 |\n|my     |12481 |\n|that   |11135 |\n|in     |11027 |\n|is     |9621  |\n|not    |8745  |\n|for    |8261  |\n|with   |8046  |\n|me     |7769  |\n|it     |7703  |\n|be     |7106  |\n|this   |6894  |\n|your   |6889  |\n|his    |6857  |\n+-------+------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1533570131018_1174495332","id":"20180709-212059_813038762","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:44:20-0500","dateFinished":"2018-08-08T10:44:22-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:82"},{"text":"%pyspark\n\n## Para quitar las stopwords\n\nfileName = \"hdfs://big0.iie.org.mx:9000/JSGP/datasets/stopwords.txt\"#Direccion a stopwords_en.txt en HDFS\n\nstopwordsDF = spark.read.text(fileName).select(removePunctuation(col('value')).alias('stword'))\n#Convierto DF to list\nstopwordsList=stopwordsDF.select(\"stword\").rdd.flatMap(lambda x: x).collect()\n\n#Comparo la columna palabras contra la lista de stopwords\nnoStopWordsDF = topWordsAndCountsDF[topWordsAndCountsDF.palabra.isin(stopwordsList) == False].orderBy(topWordsAndCountsDF.palabra.desc())\nnoStopWordsDF.show(30)\n","user":"hduser","dateUpdated":"2018-08-08T10:44:45-0500","config":{"enabled":true,"editorMode":"ace/mode/python","results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----------+------+\n|    palabra|cuenta|\n+-----------+------+\n|   zwaggerd|     1|\n|     zounds|    24|\n|       zone|     1|\n|    zodiacs|     1|\n|     zodiac|     1|\n|         zo|     1|\n|        zir|     2|\n|     zipped|     1|\n|    zephyrs|     1|\n|     zenith|     1|\n| zenelophon|     1|\n|        zed|     1|\n|      zeals|     1|\n|    zealous|     6|\n|       zeal|    33|\n|       zany|     1|\n|     zanies|     1|\n|     youyou|     1|\n|youwondrous|     1|\n|    youwell|     1|\n|     youtli|     1|\n|     youths|    10|\n|   youthful|    31|\n|    youthat|     2|\n|      youth|   277|\n|      youst|     1|\n|   yoursnot|     1|\n|      youre|    26|\n|    youpray|     1|\n|   youoften|     1|\n+-----------+------+\nonly showing top 30 rows\n\n"}]},"apps":[],"jobName":"paragraph_1533570131018_1174495332","id":"20180718-122952_561164707","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:44:45-0500","dateFinished":"2018-08-08T10:44:49-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:83"},{"text":"%pyspark\nz.show(noStopWordsDF.limit(25))","user":"hduser","dateUpdated":"2019-02-13T16:55:51-0600","config":{"lineNumbers":true,"enabled":true,"tableHide":false,"editorMode":"ace/mode/python","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{"columns":[{"name":"palabra","visible":true,"width":"*","sort":{"priority":0,"direction":"desc"},"filters":[{}],"pinned":""},{"name":"cuenta","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""}],"scrollFocus":{},"selection":[],"grouping":{"grouping":[],"aggregations":[],"rowExpandedStates":{}},"treeView":{},"pagination":{"paginationCurrentPage":1,"paginationPageSize":250}},"tableColumnTypeState":{"names":{"palabra":"string","cuenta":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default","stacked":false}},"commonSetting":{},"keys":[{"name":"palabra","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"cuenta","index":1,"aggr":"sum"}]},"helium":{}}},"editorHide":false,"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":11,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"palabra\tcuenta\nzwaggerd\t1\nzounds\t24\nzone\t1\nzodiacs\t1\nzodiac\t1\nzo\t1\nzir\t2\nzipped\t1\nzephyrs\t1\nzenith\t1\nzenelophon\t1\nzed\t1\nzeals\t1\nzealous\t6\nzeal\t33\nzany\t1\nzanies\t1\nyouyou\t1\nyouwondrous\t1\nyouwell\t1\nyoutli\t1\nyouths\t10\nyouthful\t31\nyouthat\t2\nyouth\t277\n"}]},"apps":[],"jobName":"paragraph_1533570131019_1174110583","id":"20180718-141551_302057271","dateCreated":"2018-08-06T10:42:11-0500","dateStarted":"2018-08-08T10:44:56-0500","dateFinished":"2018-08-08T10:44:59-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:84"},{"text":"%md\n# Felicidades!, finalizaste esta notebook.\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Felicidades!, finalizaste esta notebook.</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131019_1174110583","id":"20180709-212546_99083469","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:85"},{"text":"%md\n# YES!\n","dateUpdated":"2018-08-06T10:42:11-0500","config":{"enabled":true,"tableHide":false,"results":{},"editorMode":"ace/mode/markdown","editorHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>YES!</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1533570131020_1172186839","id":"20180713-184006_1193023244","dateCreated":"2018-08-06T10:42:11-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:86"}],"name":"JSGP/Practicas/2-Contador_Palabras","id":"2DMSKD9TX","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}